{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Machine Learning in Finance - Data Processing\n",
    "\n",
    "This notebook will focus on processing the data with ML techniques (RandomForest), before applying ML techniques to find the top characteristics for price prediction.\n",
    "\n",
    "***Note: This part used a package `missingpy` that requires old versions of scipy. To avoid unnecessary conflict, please uncomment the first cell to create a conda environment just for this pre-processing task. Do not forget to set the created environment as you IDE interpreter. Finally, `missingpy` has a second model which is deprecated and cause issues while importing. Then please follow the step of the video [here](https://www.youtube.com/watch?v=_886JGYt1Ts).***\n",
    "\n",
    "*Authors:* [Mina Attia](https://people.epfl.ch/mina.attia), [Arnaud Felber](https://people.epfl.ch/arnaud.felber), [Milos Novakovic](https://people.epfl.ch/milos.novakovic), [Rami Atassi](https://people.epfl.ch/rami.atassi) & [Paulo Ribeiro](https://people.epfl.ch/paulo.ribeirodecarvalho)"
   ],
   "id": "5588cd20f4297393"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#!conda create --name impute python=3.8\n",
    "#!conda activate impute\n",
    "#!/opt/anaconda3/envs/impute/bin/pip install missingpy\n",
    "#!/opt/anaconda3/envs/impute/bin/pip install scikit_learn\n",
    "#!/opt/anaconda3/envs/impute/bin/pip install pandas"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T12:05:40.617720Z",
     "start_time": "2024-05-08T12:05:40.613747Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T12:05:42.839140Z",
     "start_time": "2024-05-08T12:05:41.664604Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 2,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from missingpy.missforest import MissForest\n",
    "from data_processing import impute_data\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "824a0970c6e39a9f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data\n",
    "\n",
    "Load the dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#file_path = 'data/signed_predictors_all_wide.csv'\n",
    "\n",
    "#data = load_data_df(file_path=file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T12:05:43.479648Z",
     "start_time": "2024-05-08T12:05:43.453118Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Impute\n",
    "\n",
    "Retrieve the missing values using Machine Learning techniques. To do so, we use the API from `missingpy` and call the MissForest algorithm. MissForest imputes missing values using Random Forests in an iterative fashion."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T15:49:42.109828Z",
     "start_time": "2024-05-07T15:49:41.165028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[1.  , 2.  , 3.88],\n       [3.  , 4.  , 3.  ],\n       [2.67, 6.  , 5.  ],\n       [8.  , 8.  , 7.  ]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data... (estimated time: ~2min)\n",
      "Data loaded successfully !\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Grouping all observations per date:   0%|          | 0/36 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8427425f431d4745a6b6a831ed3506df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Status of imputation:   0%|          | 0/36 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c783131b54e1498182d4d6e68ae78bc6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "One or more columns have all rows missing.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m from_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2000\u001B[39m\n\u001B[1;32m      3\u001B[0m to_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2002\u001B[39m\n\u001B[0;32m----> 5\u001B[0m imputed_data \u001B[38;5;241m=\u001B[39m \u001B[43mimpute_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfile_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfrom_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mto_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m42\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/EPFL/Master Data Science/Semestre 2/ml_finance_folder/final_project/data_processing.py:39\u001B[0m, in \u001B[0;36mimpute_data\u001B[0;34m(file_path, from_, to_, seed)\u001B[0m\n\u001B[1;32m     37\u001B[0m char_str \u001B[38;5;241m=\u001B[39m data_to_impute\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m     38\u001B[0m \u001B[38;5;66;03m# Perform the imputation\u001B[39;00m\n\u001B[0;32m---> 39\u001B[0m data_imputed_not_full \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(data\u001B[38;5;241m=\u001B[39m\u001B[43mimputer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_to_impute\u001B[49m\u001B[43m)\u001B[49m, columns\u001B[38;5;241m=\u001B[39mchar_str)\n\u001B[1;32m     40\u001B[0m \u001B[38;5;66;03m# Concatenate the information attribute to the imputed data\u001B[39;00m\n\u001B[1;32m     41\u001B[0m data_imputed_full \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([data_info, data_imputed_not_full], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mreset_index(drop\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/missing_py/lib/python3.8/site-packages/sklearn/utils/_set_output.py:157\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[0;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[1;32m    155\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[1;32m    156\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 157\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    158\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    159\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[1;32m    160\u001B[0m         return_tuple \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    161\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[1;32m    162\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[1;32m    163\u001B[0m         )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/missing_py/lib/python3.8/site-packages/missingpy/missforest.py:556\u001B[0m, in \u001B[0;36mMissForest.fit_transform\u001B[0;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[1;32m    542\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit_transform\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params):\n\u001B[1;32m    543\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Fit MissForest and impute all missing values in X.\u001B[39;00m\n\u001B[1;32m    544\u001B[0m \n\u001B[1;32m    545\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    554\u001B[0m \u001B[38;5;124;03m        Returns imputed dataset.\u001B[39;00m\n\u001B[1;32m    555\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 556\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtransform(X)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/missing_py/lib/python3.8/site-packages/missingpy/missforest.py:450\u001B[0m, in \u001B[0;36mMissForest.fit\u001B[0;34m(self, X, y, cat_vars)\u001B[0m\n\u001B[1;32m    448\u001B[0m mask \u001B[38;5;241m=\u001B[39m _get_mask(X, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmissing_values)\n\u001B[1;32m    449\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39many(mask\u001B[38;5;241m.\u001B[39msum(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m (X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m])):\n\u001B[0;32m--> 450\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOne or more columns have all rows missing.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    452\u001B[0m \u001B[38;5;66;03m# Check cat_vars type and convert if necessary\u001B[39;00m\n\u001B[1;32m    453\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cat_vars \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mValueError\u001B[0m: One or more columns have all rows missing."
     ]
    }
   ],
   "source": [
    "file_path = 'data/signed_predictors_all_wide.csv'\n",
    "from_ = 2000\n",
    "to_ = 2002\n",
    "\n",
    "imputed_data = impute_data(file_path=file_path, from_=from_, to_=to_, seed=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T12:14:52.002844Z",
     "start_time": "2024-05-08T12:11:44.766860Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0  1    2\n",
      "0  1.0  2  1.0\n",
      "1  3.0  4  NaN\n",
      "2  NaN  6  5.0\n",
      "3  8.0  8  NaN\n"
     ]
    }
   ],
   "source": [
    "nan = np.nan\n",
    "data = pd.DataFrame([[1, 2, 1], [3, 4, nan], [nan, 6, 5], [8, 8, nan]])\n",
    "\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T12:17:40.636988Z",
     "start_time": "2024-05-08T12:17:40.605237Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[1.  , 2.  , 1.  ],\n       [3.  , 4.  , 3.12],\n       [4.29, 6.  , 5.  ],\n       [8.  , 8.  , 4.08]])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = MissForest(missing_values=np.nan,\n",
    "                     criterion=('squared_error', 'gini'),\n",
    "                     max_features='sqrt',\n",
    "                     random_state=1337)\n",
    "data_imputed = imputer.fit_transform(data)\n",
    "data_imputed"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T12:17:43.438865Z",
     "start_time": "2024-05-08T12:17:42.730026Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
